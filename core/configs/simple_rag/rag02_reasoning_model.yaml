# core/configs/rag_reasoning_model.yaml

""" 
Compare the performance of different LLMs for RAG.
- whether the reasoning model is better than the normal model
- whether the large model is better than the small model

Tested on InterDocumentQA (Frames).
"""

#  Llama3.1 (8B)
simple_rag_02_01:
  dataset: 
    name: frames
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
  model:
    llm_id: llama3.1
  retrieval:
    faiss_search: "flatl2"
    top_k: 10

# DeepSeek-R1-8B
simple_rag_02_02:
  dataset:
    name: frames
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
  model:
    llm_id: deepseek-r1-8b
  retrieval:
    faiss_search: "flatl2"
    top_k: 10

# Phi4(14B)
simple_rag_02_03:
  dataset:
    name: frames
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
  model:
    llm_id: phi4
  retrieval:
    faiss_search: "flatl2"
    top_k: 10

# DeepSeek-R1-14B
simple_rag_02_04:
  dataset:
    name: frames
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
  model:
    llm_id: deepseek-r1-14b
  retrieval:
    faiss_search: "flatl2"
    top_k: 10
