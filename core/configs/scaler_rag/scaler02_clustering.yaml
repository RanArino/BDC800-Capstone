# core/configs/scaler_rag/scaler02_clustering.yaml

# Compare the performance of different LLMs for RAG.
# - whether the gmm is better than the normal model
# - whether the gmm is better than the kmean
#
# Tested on IntraDocumentQA (Qasper) and InterDocumentQA (Frames).

# GMM
#  IntraDocumentQA (Qasper) & GMM
scaler_rag_02_01:
  dataset:
    name: qasper
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
    clustering:
      method: "gmm"
    dim_reduction:
      method: "pca"
      n_components: 15
  retrieval_generation:
    faiss_search: "flatl2"
    top_k: 5
    llm_id: gemini-1.5-flash-8b

# InterDocumentQA (Frames) & GMM
scaler_rag_02_02:
  dataset:
    name: frames
    number_of_qas: 500
  summarizer:
    llm_id: llama3.2:1b
    output_tokens: 256
    embedding_id: huggingface-multi-qa-mpnet
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
    clustering:
      method: "gmm"
    dim_reduction:
      method: "pca"
      n_components: 15
  retrieval_generation:
    faiss_search: "flatl2"
    top_k: 10
    llm_id: gemini-1.5-flash-8b

# IntraDocumentQA (NarrativeQA) & GMM 
#  Same as scaler_rag_01_02
scaler_rag_02_03:
  dataset:
    name: narrativeqa
    number_of_docs: 100
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
    clustering:
      method: "gmm"
    dim_reduction:
      method: "pca"
      n_components: 15
  retrieval_generation:
    faiss_search: "flatl2"
    top_k: 5
    llm_id: gemini-1.5-flash-8b

# InterDocumentQA(MultiHopRAG) & GMM
#  Same as scaler_rag_01_04
scaler_rag_02_04:
  dataset:
    name: multihoprag
    number_of_qas: 500
  summarizer:
    llm_id: llama3.2:1b
    output_tokens: 256
    embedding_id: huggingface-multi-qa-mpnet
  chunker:
    mode: sentence
    size: 100
    overlap: 0.2
    embedding_id: huggingface-multi-qa-mpnet
    clustering:
      method: "gmm"
    dim_reduction:
      method: "pca"
      n_components: 15
  retrieval_generation:
    faiss_search: "flatl2"
    top_k: 10
    llm_id: gemini-1.5-flash-8b