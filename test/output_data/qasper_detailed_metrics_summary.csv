qa_id,query,ground_truth,llm_answer,rouge1_p,rouge1_r,rouge1_f,rouge2_p,rouge2_r,rouge2_f,rougeL_p,rougeL_r,rougeL_f,bleu,cosine_sim,self_checker
q0,What is the seed lexicon?,a vocabulary of positive and negative predicates that helps determine the polarity score of an event,The seed lexicon consists of 15 positive words and 15 negative words. It is used to assign polarity ,0.1836734693877551,0.5625,0.27692307692307694,0.020833333333333332,0.06666666666666667,0.031746031746031744,0.14285714285714285,0.4375,0.2153846153846154,0.010956421443241472,0.6516448259353638,Yes
q1,What are the results?,"Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL",The results are shown in Table TABREF23 (accuracy) and the text does not specify what these results ,0.08571428571428572,0.028846153846153848,0.04316546762589928,0.0,0.0,0.0,0.08571428571428572,0.028846153846153848,0.04316546762589928,0.0013333020376430865,0.27117919921875,Yes
q2,How are relations used to propagate polarity?,"based on the relation between events, the suggested polarity of one event can determine the possible","According to the context, discourse relations (specifically Cause and Concession) are used to effici",0.16176470588235295,0.5238095238095238,0.24719101123595508,0.0,0.0,0.0,0.11764705882352941,0.38095238095238093,0.17977528089887637,0.008833706365998324,0.5127675533294678,Yes
q3,How big is the Japanese data?,"7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were ext","The context does not mention a specific ""Japanese data"" but rather mentions the use of Japanese BERT",0.12244897959183673,0.2857142857142857,0.1714285714285714,0.0,0.0,0.0,0.10204081632653061,0.23809523809523808,0.14285714285714285,0.010959933475393717,0.46423614025115967,No
q4,How big are improvements of supervszed learning results trained on smalled labeled data enhanced wit,3%,"The question is a bit convoluted, but I'll try to provide an answer based on the context.

According",0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0023184451980916686,0.046845193952322006,No
q5,How does their model learn using mostly raw data?,by exploiting discourse relations to propagate polarity from seed predicates to final sentiment pola,"The model learns by using semi-supervised learning, where it uses a combination of labeled and unlab",0.09210526315789473,0.5,0.15555555555555556,0.0,0.0,0.0,0.06578947368421052,0.35714285714285715,0.1111111111111111,0.006790098610370757,0.30861735343933105,Yes
q6,How big is seed lexicon used for training?,30 words,"According to the context, the seed lexicon consisted of 15 positive words and 15 negative words.",0.0625,0.5,0.1111111111111111,0.0,0.0,0.0,0.0625,0.5,0.1111111111111111,0.021476912089159056,0.36031097173690796,Yes
q7,How do the various social phenomena examined manifest in different types of communities?,Dynamic communities have substantially higher rates of monthly user retention than more stable commu,The answer cannot be determined from the provided context as it does not mention anything about how ,0.23728813559322035,0.1590909090909091,0.19047619047619047,0.0,0.0,0.0,0.13559322033898305,0.09090909090909091,0.10884353741496598,0.012501289805433146,0.35340750217437744,No
q8,How did the select the 300 Reddit communities for comparison?,They selected all the subreddits from January 2013 to December 2014 with at least 500 words in the v,The provided context does not mention selecting 300 Reddit communities for comparison at all. The te,0.21052631578947367,0.27906976744186046,0.24,0.03571428571428571,0.047619047619047616,0.04081632653061224,0.14035087719298245,0.18604651162790697,0.15999999999999998,0.01705568954278245,0.5188770890235901,No
